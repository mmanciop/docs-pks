---
title: Scaling Ingress Resources (NSX-T only)
owner: PKS-NSX-T
---

This topic describes how to scale ingress resources. 

<p class="note"><strong>Note:</strong> This feature requires NCP v2.5.1 or later.</p>

## <a id='ingress-scaling-about'></a> Overview

For each Kubernetes cluster provisioned by Enterprise PKS with NSX-T, there are 2 layer 7 virtual servers 
(HTTP and HTTPS) attached to the cluster load balancer service that perform ingress routing. 

Using [custom resources](https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/#custom-resources), 
Enterprise PKS v1.6 gives you the ability to scale the virtual servers created for ingress.  

You can use the LoadBalancer CRD to scale the load balancer for ingress routing.  

### <a id='nsxLoadBalancerMonitors-actions'></a> Determine Your Load Balancer's Status

You can use the NSXLoadBalancerMonitor CRD to monitor your NSX-T load balancer service, 
including traffic, usage and health score information. 
The NSXLoadBalancerMonitor CRD returns two health scores for the current performance of load balancers:

- `servicePressureIndex` which represents an overall health score for the NSX-T load balancer service.  
- `infraPressureIndex` which represents the heath score of the NSX-T Edge Node that is running 
the load balancer and associated virtual servers.  

If the health score is poor for one of the layer 4 load balancers, you can use a network profile to 
[increase the size of the NSX-T load balancer service](./network-profiles-ncp-lb.html).  

If the health score is poor for the layer 7 ingress load balancers, you can use the 
[LoadBalancer CRD](#LoadBalancer) to manually scale ingress.  

Based on the health score the user can decide what action to take. The table below summarizes the actions that you can take based on the health scores.

servicePressureIndex | infraPressureIndex | Cluster Manager  | Infrastructure Admin
---------------------|--------------------|------------------|--------------------
LOW or WARM          | LOW or WARM        | NONE             | NONE
LOW or WARM          | HIGH               | Alert infra admin| Move the LBS from the CRITICAL Edge Node to another Edge Node.
HIGH                 | LOW or WARM        | Resolve the LBS health score by [scaling the ingress LB](./nsxt-ingress-scale.html#LoadBalancer) and, if necessary, by increasing the size of the LBS using [network profile](./network-profiles-ncp-lb.html). | NONE 
HIGH                 | HIGH               | Alert infra admin; Resolve the LBS health score by [scaling the ingress LB](./nsxt-ingress-scale.html#LoadBalancer) and, if necessary, by increasing the size of the LBS using [network profile](./network-profiles-ncp-lb.html). | Move the LBS from the CRITICAL Edge Node to another Edge Node.  

For more information about monitoring using the NSXLoadBalancerMonitor CRD see [Monitoring Ingress Resources (NSX-T only)](nsxt-ingress-monitor.html).  

## <a id='LoadBalancer'></a>Scale Ingress Load Balancers Using the LoadBalancer CRD

The LoadBalancer CRD provides you with an interactive method to scale the load balancer 
for ingress routing. 

Use the LoadBalancer CRD to create a new ingress load balancer after monitoring the health status of the load balancer service. 
used the NSXLoadBalancerMonitor CRD to check 
, you can . 
Then you annotate the Kubernetes K8S ingress resource with the newly created ingress load balancer. 
NCP will attach the ingress rules to the scaled out load balancer.

### <a id='LoadBalancer-example'></a> Create a New Ingress Load Balancer

1. To configure a new ingress load balancer, configure a new YAML file as follows:

    ```
    apiVersion: vmware.com/v1alpha1
    kind: LoadBalancer
    metadata:
      name: LB-NAME
    spec:
      httpConfig: HTTP-CONFIG
        virtualIP: IP-ADDRESS  
        port: PORT
        tls:
          port: TLS-PORT
          secretName: SECRET-NAME
          secretNamespace: SECRET-NAMESPACE
        xForwardedFor: FORWARD-TYPE
        affinity:
          type: IP-SOURCE
          timeout: TIMEOUT
      size: SIZE
      virtualNetwork: NETWORK-NAME
    status:
      httpVirtualIP: V-IP-ADDRESS
    ```

    Where:
    * `LB-NAME` is the display name of the loadBalancer.  
    * `HTTP-CONFIG` (Optional) is the config to support http/https route on the loadBalancer. Set as `httpConfig: {}` to apply default settings.  
    * `IP-ADDRESS` (Optional) is the virtual IP address. Defaults to `auto_allocate`.  
    * `PORT` (Optional) is the port. Defaults to `80`.  
    * `TLS-PORT` (Optional) is the TLS port. Defaults to `443`.  
    * `SECRET-NAME` (Optional) is the TLS secret name. Defaults to `nil`.  
    * `SECRET-NAMESPACE` (Optional) is the TLS secret namespace. Defaults to `nil`.  
    * `FORWARD-TYPE` (Optional) is the forward type. Supported values are: `INSERT` and `REPLACE`. Defaults to `nil`.  
    * `IP-SOURCE` (Optional) is the source IP. Supported values are: `sourceIP` and `cookie`.  
    * `TIMEOUT` (Optional) is the connection timeout. Defaults to `10800`.  
    * `SIZE` (Optional) is the ingress load balancer size. Supported values are: `SMALL` and `MEDIUM`. Defaults to `SMALL`.  
    * `NETWORK-NAME` (Optional) is the virtual network name. Defaults to `nil`.  
    * `V-IP-ADDRESS` is the external IP address for http/https virtual server. The external IP address can be auto-allocated or user specified.  

1. To create a new ingress load balancer run the following command:

    ```
    kubectl apply –f YAML-FILE
    ```

    Where `YAML-FILE` is the filename of a the load balancer configuration YAML file.    
<br>
    For example:  
    <pre class="terminal">
    \# kubectl apply –f lb.yaml
    apiVersion: vmware.com/v1alpha1
    kind: LoadBalancer
    metadata:
      name: cluster1\_lbs0
    spec:
      httpConfig: 
        virtualIP: 
        port: 233 
        tls:
          port: 2333 
          secretName: default\_secret 
          secretNamespace: default 
        xForwardedFor: INSERT 
        affinity:
          type: source\_ip 
          timeout: 100 
      size: MEDIUM 
      virtualNetwork: virtualnetwork1 
    status:
      httpVirtualIP: &lt;realized external ip&gt;  
    </pre>
<p class="note"><strong>Note:</strong> You must deploy the the new ingress load 
balancer in the same namesapce where you deploy the ingress resource.
</p>
1. To configure a Kubernetes ingress resource with the new ingress load balancer, configure a new YAML file as follows:

    ```
    apiVersion:  extensions/v1beta1
    kind: Ingress
    metadata:
      name: ING-NAME
      annotations:
        nsx/loadbalancer: LB-NAME 
    spec:
      rules:
      - host: HOST-NAME
        http:
          paths:
          - path: HTTP-PATH
              backend:
                serviceName: SERVICE-NAME
                servicePort: SERVICE-PORT
    ```

    Where:
    * `ING-NAME` is the name of the ingress resource.
    * `LB-NAME` is the display name of the loadBalancer.  
    * `HOST-NAME` is the host name.
    * `HTTP-PATH` is the HTTP path.
    * `SERVICE-NAME` is the http backend service name.
    * `SERVICE-PORT` is the http backend service port.

1. To annotate the Kubernetes ingress resource with the newly created ingress load balancer, run the following command:

    ```
    kubectl apply –f YAML-FILE
    ```

    Where `YAML-FILE` is the filename of a the Kubernetes ingress resource configuration YAML file.    
<br>
    For example:  
    <pre class="terminal">
    \# kubectl apply –f ingress.yaml
    apiVersion: extensions/v1beta1
    kind: Ingress
    metadata:
      name: svc-ingress1
      annotations:
        nsx/loadbalancer: cluster1\_lbs0
    spec:
      rules:
      \- host: test.com
        http:
          paths:
          \- path: /testpath
              backend:
                serviceName: svc1
                servicePort: 80
    </pre>
